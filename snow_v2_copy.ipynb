{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from kan import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据并随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc=r\"D:\\Data\\snow_cover_V2\"\n",
    "x_test=np.load(os.path.join(data_loc,\"x_test_d.npy\"),mmap_mode=\"r\")\n",
    "y_test=np.load(os.path.join(data_loc,\"y_test_d.npy\"),mmap_mode=\"r\")\n",
    "x_train=np.load(os.path.join(data_loc,\"x_train_d.npy\"),mmap_mode=\"r\")\n",
    "y_train=np.load(os.path.join(data_loc,\"y_train_d.npy\"),mmap_mode=\"r\")\n",
    "# print(\"x_test_d's shape is\",x_test.shape)\n",
    "# print(\"y_test_d's shape is\",y_test.shape)\n",
    "# print(\"x_train_d's shape is\",x_train.shape)\n",
    "# print(\"y_train_d's shape is\",y_train.shape)\n",
    "# 进行随机采样，采样 0.1% 的数据\n",
    "sample_size = int(0.001 * len(x_train))\n",
    "sample_indices = np.random.choice(len(x_train), size=sample_size, replace=False)\n",
    "x_train_sample = x_train[sample_indices]\n",
    "y_train_sample = y_train[sample_indices]\n",
    "\n",
    "sample_size2 = int(0.001 * len(x_test))\n",
    "sample_indices2 = np.random.choice(len(x_test), size=sample_size2, replace=False)\n",
    "x_test_sample = x_test[sample_indices2]\n",
    "y_test_sample = y_test[sample_indices2]\n",
    "# print(x_train_sample.shape)  # 输出采样后的数据形状\n",
    "# print(y_train_sample.shape)\n",
    "# print(x_test_sample.shape)  \n",
    "# print(y_test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "制作数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        初始化数据集，使用x_sample和y_sample划分为训练和测试集\n",
    "        :param x_sample: 特征的numpy数组\n",
    "        :param y_sample: 标签的numpy数组\n",
    "        :param test_size: 测试集比例\n",
    "        :param random_state: 随机种子\n",
    "        \"\"\"\n",
    "        # # 划分训练集和测试集\n",
    "        # x_train, x_test, y_train, y_test = train_test_split(\n",
    "        #     x_sample, y_sample, test_size=test_size, random_state=random_state\n",
    "        # )\n",
    "\n",
    "        # 将划分好的数据转为Tensor\n",
    "        # 存储数据集，使用 torch.tensor 从 NumPy 数组或其他格式转换为张量，并将其移动到指定设备（如 GPU）。\n",
    "        self.data_dict = {\n",
    "            'train_input': torch.tensor(x_train, dtype=torch.float32).to(device=device),\n",
    "            'train_label': torch.tensor(y_train, dtype=torch.float32).to(device=device),\n",
    "            'test_input': torch.tensor(x_test, dtype=torch.float32).to(device=device),\n",
    "            'test_label': torch.tensor(y_test, dtype=torch.float32).to(device=device)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回训练数据的长度\n",
    "        return len(self.data_dict['train_label'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 根据索引返回训练数据和标签\n",
    "        return {\n",
    "            'train_input': self.data_dict['train_input'][idx],\n",
    "            'train_label': self.data_dict['train_label'][idx],\n",
    "            'test_input': self.data_dict['test_input'][idx % len(self.data_dict['test_input'])],  # 循环访问测试数据\n",
    "            'test_label': self.data_dict['test_label'][idx % len(self.data_dict['test_label'])]   # 循环访问测试标签\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化数据集\n",
    "dataset = CustomDataset(x_train_sample,y_train_sample,x_test_sample,y_test_sample)\n",
    "# 创建数据加载器\n",
    "dataloader = DataLoader(dataset, batch_size=500, shuffle=True)\n",
    "\n",
    "# print(dataloader)\n",
    "# # 验证数据集\n",
    "# for batch_data in dataloader:\n",
    "#     print(batch_data[\"test_label\"])\n",
    "#     break  # 只打印第一个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a KAN: 2D inputs, 1D output, and 5 hidden neurons. cubic spline (k=3), 5 grid intervals (grid=5).\n",
    "model = KAN(width=[6,3,1], grid=5, k=3, seed=0,device=device)\n",
    "model(dataset.data_dict[\"train_input\"])\n",
    "model.plot(beta=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练集的平均误差（MAE）\n",
    "def train_mae():\n",
    "    # 计算预测值和真实值之间的绝对误差\n",
    "    errors = torch.abs(model(dataset.data_dict['train_input'])[:, 0] - dataset.data_dict['train_label'][:, 0])\n",
    "    # 计算绝对误差的平均值\n",
    "    return torch.mean(errors)\n",
    "\n",
    "# 计算测试集的平均误差（MAE）\n",
    "def test_mae():\n",
    "    # 计算预测值和真实值之间的绝对误差\n",
    "    errors = torch.abs(model(dataset.data_dict['test_input'])[:, 0] - dataset.data_dict['test_label'][:, 0])\n",
    "    # 计算绝对误差的平均值\n",
    "    return torch.mean(errors)\n",
    "\n",
    "#计算均方差（MSE）\n",
    "def train_mse():\n",
    "    errors = (model(dataset.data_dict['train_input'])[:, 0] - dataset.data_dict['train_label'][:, 0]) ** 2\n",
    "    return torch.mean(errors)\n",
    "\n",
    "def test_mse():\n",
    "    errors = (model(dataset.data_dict['test_input'])[:, 0] - dataset.data_dict['test_label'][:, 0]) ** 2\n",
    "    return torch.mean(errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一次训练\n",
    "\n",
    "这个训练有几个超参数是需要调整的，还有prun减枝的时候那个阈值也需要调整。\n",
    "\n",
    "lamb、lamb_entropy这个都是正则化参数可以看文档 \n",
    "\n",
    "[API 6: Training Hyperparamters](https://github.com/KindXiaoming/pykan/blob/master/tutorials/API_demo/API_6_training_hyperparameter.ipynb)\n",
    "\n",
    "lamb、lamb_entropy都是越大，越稀疏化\n",
    "\n",
    "然后就是这个默认的learning rate（lr）为1.0很大，看看要不要调小点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "res=model.fit(dataset.data_dict, opt=\"LBFGS\", steps=20, lamb=0.01, lamb_entropy=10, metrics=(train_mae,train_mse,test_mae,test_mse))\n",
    "train_loss=res[\"train_loss\"]\n",
    "test_loss=res[\"test_loss\"]\n",
    "\n",
    "train_mae=res[\"train_mae\"][-1]\n",
    "train_mse=res[\"train_mse\"][-1]\n",
    "test_mae=res[\"test_mae\"][-1]\n",
    "test_mse=res[\"test_mse\"][-1]\n",
    "# 打印结果\n",
    "print(f\"Train MAE: {train_mae:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "# 绘制损失图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "plt.plot(test_loss, label='Test Loss', color='orange')\n",
    "plt.title('Train and Test Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#绘制模型\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prune()\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次训练+网格细化（第三次训练？？？）+第四次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "res=model.fit(dataset.data_dict, opt=\"LBFGS\", steps=20, lamb=0.01, lamb_entropy=10, metrics=(train_mae,train_mse,test_mae,test_mse))\n",
    "train_loss=res[\"train_loss\"]\n",
    "test_loss=res[\"test_loss\"]\n",
    "\n",
    "train_mae=res[\"train_mae\"][-1]\n",
    "train_mse=res[\"train_mse\"][-1]\n",
    "test_mae=res[\"test_mae\"][-1]\n",
    "test_mse=res[\"test_mse\"][-1]\n",
    "# 打印结果\n",
    "print(f\"Train MAE: {train_mae:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "# 绘制损失图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "plt.plot(test_loss, label='Test Loss', color='orange')\n",
    "plt.title('Train and Test Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#绘制模型\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.refine(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "res=model.fit(dataset.data_dict, opt=\"LBFGS\", steps=20, lamb=0.01, lamb_entropy=10, metrics=(train_mae,train_mse,test_mae,test_mse))\n",
    "train_loss=res[\"train_loss\"]\n",
    "test_loss=res[\"test_loss\"]\n",
    "\n",
    "train_mae=res[\"train_mae\"][-1]\n",
    "train_mse=res[\"train_mse\"][-1]\n",
    "test_mae=res[\"test_mae\"][-1]\n",
    "test_mse=res[\"test_mse\"][-1]\n",
    "# 打印结果\n",
    "print(f\"Train MAE: {train_mae:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "# 绘制损失图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "plt.plot(test_loss, label='Test Loss', color='orange')\n",
    "plt.title('Train and Test Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#绘制模型\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "符号回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"auto\" # \"manual\"\n",
    "\n",
    "if mode == \"manual\":\n",
    "    # manual mode\n",
    "    model.fix_symbolic(0,0,0,'sin');\n",
    "    model.fix_symbolic(0,1,0,'x^2');\n",
    "    model.fix_symbolic(1,0,0,'exp');\n",
    "elif mode == \"auto\":\n",
    "    # automatic mode\n",
    "    lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
    "    model.auto_symbolic(lib=lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan.utils import ex_round\n",
    "\n",
    "SR=ex_round(model.symbolic_formula()[0][0],4)\n",
    "print(SR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
